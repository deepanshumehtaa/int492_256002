{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for Small Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การทดลองสร้าง convolutional neural network สำหรับจำแนกประเภทรูปภาพเป็นสองคลาส (สุนัข และ แมว)\n",
    "\n",
    "ข้อมูลแบ่งเป็นสามส่วนคือ training dataset, validation dataset, test dataset\n",
    "\n",
    "* **training dataset**. เป็นชุดข้อมูลตัวอย่างสำหรับใช้เทรนโมเดลเพื่อหาค่าโมเดลพารามิเตอร์ที่เหมาะสม\n",
    "* **validation dataset**. เป็นชุดข้อมูลสำหรับเลือกค่า hyperparameters (คือพารามิเตอร์ที่ไม่ได้มาจากการเทรน เช่น จำนวน hidden layers ที่เหมาะสม, ค่า learning rate, ...) \n",
    "* **test dataset**. เป็นชุดข้อมูลสำหรับใช้เปรียบเทียบประสิทธิภาพ (unbiased evaluation) ของโมเดลที่ได้จากการเทรน "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from a file system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_dir = 'data/cats_and_dogs_small/train'\n",
    "validation_dir = 'data/cats_and_dogs_small/validation'\n",
    "test_dir = 'data/cats_and_dogs_small/test'\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('total train cat images:', len(os.listdir(train_cats_dir)))\n",
    "print('total train dog images:', len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลที่แสดงใน cell ก่อนหน้า \n",
    "* training set ประกอบด้วย รูปภาพแมว 1000 รูป และ รูปภาพสุนัข 1000 รูป \n",
    "* validation set ประกอบด้วย รูปภาพแมว 500 รูป และ รูปภาพสุนัข 500 รูป\n",
    "* test set ประกอบด้วย รูปภาพแมว 500 รูป และ รูปภาพสุนัข 500 รูป"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Pre-process Image Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เนื่องจากข้อมูลรูปภาพมีขนาดไม่เท่ากัน ก่อนป้อนข้อมูลให้กับนิวรอนเน็ตเวิร์ก เราจำเป็นต้องแปลงข้อมูลรูปภาพในชุดข้อมูลให้อยู่ในรูปแบบและสเกลที่เหมาะสม ตรงกันทั้ง training set, validation set, และ test set ก่อน\n",
    "\n",
    "โดยจะใช้คลาส `ImageDataGenerator` ในแพ็คเกจ `keras.preprocessing.image` สำหรับ pre-process ข้อมูลด้วย operations ดังต่อไปนี้ คือ\n",
    "* **Rescale**. แปลงช่วงของค่าของข้อมูลให้อยู่ในช่วง 0.0 ถึง 1.0 โดยการหารค่าของข้อมูลทุกตัวด้วยค่าสูงสุดที่เป็นไปได้ (สำหรับข้อมูลรูปภาพ ค่าในแต่ละพิกเซล จะมีค่าตั้งแต่ 0 ถึง 255)\n",
    "* **Resize**. แปลงขนาดของรูปภาพให้มีขนาด 150x150 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create ImageDataGenerator object, set rescaler with the value 1.0/255 (normalize to 0-1)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a Generator object for training dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_dir,\n",
    "                target_size=(150, 150),\n",
    "                batch_size=20,\n",
    "                class_mode='binary')\n",
    "\n",
    "# Create a Generator object for validation dataset\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                validation_dir,\n",
    "                target_size=(150, 150),\n",
    "                batch_size=20,\n",
    "                class_mode='binary')\n",
    "\n",
    "# Create a Generator object for test dataset\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                test_dir,\n",
    "                target_size=(150, 150),\n",
    "                batch_size=20,\n",
    "                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape of images in the training set\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "กำหนดโครงสร้างของ convnet โดยโมเดลของเราจะประกอบด้วยเลเยอร์ต่างๆ ดังนี้\n",
    "\n",
    "1. Convolutional Layer ลำดับที่ 1. ประกอบด้วย ReLU filters ขนาด 3x3 จำนวน 32 ฟิลเตอร์, อินพุทของเลเยอร์นี้คือ ข้อมูลรูปภาพสีขนาด 150x150x3, เอาท์พุทมีมิติ 148x148x32\n",
    "2. Max Pooling Layer ลำดับที่ 1. ประกอบด้วย ReLU filters ขนาด 2x2 จำนวน 32 ฟิลเตอร์, เอาท์พุทมีมิติ 74x74x32\n",
    "3. Convolutional Layer ลำดับที่ 2. ประกอบด้วย filters ขนาด 3x3x32 จำนวน 64 ฟิลเตอร์, เอาท์พุทมีมิติ 72x72x64\n",
    "4. Max Pooling Layer ลำดับที่ 2. ประกอบด้วย filters ขนาด 2x2 จำนวน 64 ฟิลเตอร์, เอาท์พุทมีมิติ 36x36x64\n",
    "5. Convolutional Layer ลำดับที่ 3. ประกอบด้วย filters ขนาด 3x3x64 จำนวน 128 ฟิลเตอร์, เอาท์พุทมีมิติ 34x34x128\n",
    "6. Max Pooling Layer ลำดับที่ 3. ประกอบด้วย filters ขนาด 2x2 จำนวน 128 ฟิลเตอร์, เอาท์พุทมีมิติ 17x17x128\n",
    "7. Convolutional Layer ลำดับที่ 4. ประกอบด้วย filters ขนาด 3x3x128 จำนวน 128 ฟิลเตอร์, เอาท์พุทมีมิติ 15x15x128\n",
    "8. Max Pooling Layer ลำดับที่ 4. ประกอบด้วย filters ขนาด 2x2 จำนวน 128 ฟิลเตอร์, เอาท์พุทมีมิติ 7x7x128\n",
    "9. Flatten Layer. แปลงข้อมูลอินพุทขนาด 7x7x128 เป็น 6272x1\n",
    "10. Dense Layer ลำดับที่ 1. นิวรอนชนิด ReLU จำนวน 512 เชื่อมต่อกับเลเยอร์ก่อนหน้าและเลเยอร์ถัดไปแบบ fully connected\n",
    "11. Output Layer. ประกอบด้วยนิวรอนขนิด sigmoid จำนวน 1 นิวรอน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Conv2D(128,(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Conv2D(128,(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เทรนโมเดล โดยกำหนด loss function เป็น binary crossentropy, ใช้ optimizer เป็น RMSprop สำหรับวิธีการวัดประสิทธิภาพโมเดลใช้ accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "            train_generator, steps_per_epoch=100, \n",
    "            epochs=100,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model for Later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### แสดงกราฟ Training Accuracy และ Validation Accuracy ในแต่ละรอบของการเทรนโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
