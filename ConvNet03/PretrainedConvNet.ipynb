{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning ด้วย Pretrained CONVNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pretrained network** คือ convolutional network สำหรับการจำแนกประเภทของรูปภาพ ที่ผ่านการเทรนด้วยชุดข้อมูลขนาดใหญ่แล้ว โดยหากชุดข้อมูลที่ใช้เทรนมีขนาดใหญ่และมีความหลากหลายเพียงพอแล้ว ฟีเจอร์เชิงพื้นที่แบบมีลำดับขั้น (spatial hierarchy of features) ที่ pretrained convnet เรียนรู้ได้นั้น สามารถนำไปใช้เป็นโมเดลพื้นฐานสำหรับรูปทรงในการงานด้านการประมวลผลภาพ (computer vision) ปัญหาอื่น ที่ต่างไปจากเดิมได้ \n",
    "\n",
    "แนวความคิดในการนำ pretrained convnet ไปใช้ใน computer vision task ที่ต่างจาก computer vision task ที่โมเดลถูกสร้างขึ้นมานี้ เรียกว่า **transfer learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![การนำ Pretrained CONVNET มาใช้](images/fig1.jpg)\n",
    "\n",
    "<center>**รูปที่ 1 การใช้ Pretrained convolutional neural network เป็น Feature Extractor สำหรับ classifier ตัวใหม่**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากรูปที่ 1 จะเห็นว่า เราจะไม่นำส่วนที่เป็น dense layers ในตอนท้ายของ convnet มาใช้ เนื่องจากเหตุผลหลักสองประการคือ ข้อแรกฟีเจอร์ที่เรียนรู้ได้ในส่วนของ dense layers นี้จะเป็นฟีเจอร์ที่เฉพาะเจาะจงกับปัญหาที่ใช้ในการสร้าง pretrained model ขึ้นมา และข้อสองฟีเจอร์ที่เรียนรู้ได้ในส่วนของ dense layers จะไม่มีข้อมูลเกี่ยวกับตำแหน่งเหลืออยู่ ดังนั้นฟีเจอร์ที่เรียนรู้ได้ใน dense layers นี้ จึงไม่มีประโยชน์กับการประมวลผลภาพที่จำเป็นต้องใช้ข้อมูลเกี่ยวกับตำแหน่งของวัตถุ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ไลบารี่ keras และ deeplearning4j ได้เตรียม pretrained convnet โมเดลไว้ให้กับผู้ใช้หลายตัว โดยสำหรับไลบารี่ deeplearning4j เราสามารถเลือกใช้ pretrained model ได้จากแพกเกจ \n",
    "```org.deeplearning4j.zoo``` (ข้อมูลเพิ่มเติมที่ https://deeplearning4j.org/model-zoo) สำหรับไลบารี่ keras pretrained model จะอยู่ในโมดูล ```keras.applications``` (ข้อมูลเพิ่มเติมที่ https://keras.io/applications)\n",
    "\n",
    "ตัวอย่าง pretrained convnet ใน keras และ deeplearning4j\n",
    "* VGG16\n",
    "* VGG19\n",
    "* ResNet50\n",
    "* InceptionResNetV1\n",
    "* InceptionResNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่างการนำ Pretrained CONVNET (VGG16) มาใช้สร้าง Cat/Dog Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "import os \n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# setup dataset paths\n",
    "base_dir = 'data/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# setup the Image data generator\n",
    "## augment the training dataset\n",
    "## by rotation, shifting, shearing, zoom, flip operations\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=40,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size =(150, 150),\n",
    "            batch_size=20,\n",
    "            class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_dir,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=20,\n",
    "            class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=20,\n",
    "            class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "# load the pretrained model\n",
    "conv_base = VGG16(weights='imagenet',   # used weights derived by pre-training on ImageNet \n",
    "                  include_top=False,    # do not include the dense layer\n",
    "                  input_shape=(150, 150, 3))  # if not specified, \n",
    "                                              # the network will be able \n",
    "                                              # to process input of any size\n",
    "        \n",
    "# Freeze the network by setting its trainable attribute to False\n",
    "# this is done to prevent weights in the convolutional base from \n",
    "# being updated during training.\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a summary of model architecture\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### สร้างโมเดล โดยการเพิ่ม Dense Layer บน convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### เทรนโมเดลใหม่"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=100,\n",
    "            epochs=30,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### บันทึกโมเดลไว้ใช้งานภายหลัง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small-vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### พล็อตกราฟแสดงประสิทธิภาพระหว่างการเทรน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Accuracy Plots\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Loss Plots\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ประเมินประสิทธิภาพของโมเดลที่ได้บน test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### สรุป"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convolutional neural network (convnet) เป็นโมเดลการเรียนรู้เชิงลึกที่เหมาะสำหรับการประมวลผลภาพ (computer vision)\n",
    "\n",
    "* เราสามารถสร้าง convnet เองทั้งหมด หรือสร้างต่อยอดจาก pretrained models ต่างๆ เช่น VGG16, VGG19, ResNet\n",
    "\n",
    "* สำหรับโปรเจ็กต์ที่ชุดข้อมูลมีขนาดเล็ก ปัญหาที่มักพบบ่อยคือ overfitting (โมเดลที่ได้มีประสิทธิภาพที่ดีบนชุดเทรน แต่ไม่ดีบนชุดทดสอบ) วิธีการแก้ปัญหา overfitting มีหลายวิธี เช่น การใช้ dropout layers, การทำ data augmentation, หรือการใช้ Pretrained models\n",
    "   * ในไลบารี keras และ deeplearning4j มี Pretrained Models เตรียมไว้ให้ใช้งานได้หลายโมเดล เราสามารถนำส่วน convolutional layers ของ pretrained models มาใช้สร้าง convnet ตัวใหม่ได้ โดยการเพิ่ม dense layers เข้าไปบน convolutional base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
