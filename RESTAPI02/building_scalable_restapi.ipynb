{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### การสร้าง Deep Learning REST API ที่สามารถประมวลผลอินพุทแบบ batch ได้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เพื่อให้ deep learning API สามารถจัดการกับ requests ปริมาณมากได้ เราจะเพิ่มระบบ message queue และ message broker เข้าไปในสถาปัตยกรรมของระบบ API ดังรูปที่ 1.\n",
    "\n",
    "![](apiarch.png)\n",
    "<b><center>รูปที่ 1. Deep Learning REST API ที่มีระบบ message queue และ message broker.</center></b>\n",
    "\n",
    "*** หมายเหตุ เนื้อหาใน notebook นี้ดัดแปลงมาจาก https://www.pyimagesearch.com/2018/01/29/scalable-keras-deep-learning-rest-api/ ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยเครื่องมือที่เราจะนำมาใช้สร้างระบบดังกล่าว ประกอบด้วย\n",
    "* Keras (https://keras.io/) ใช้สำหรับโหลดโมเดล และทำนายประเภทของรูปภาพ\n",
    "* Redis (https://redis.io/) ใช้สำหรับสร้างระบบ message queue/borker\n",
    "* Flask (http://flask.pocoo.org/) ใช้เป็น web server สำหรับ REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ขั้นตอนแรก เริ่มด้วยการติดตั้ง Redis\n",
    "```\n",
    "$ wget http://download.redis.io/redis-stable.tar.gz\n",
    "$ tar xvzf redis-stable.tar.gz\n",
    "$ cd redis-stable\n",
    "$ make\n",
    "$ sudo make install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Redis server ด้วยคำสั่งต่อไปนี้\n",
    "```\n",
    "$ redis-server\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตรวจสอบว่า Redis server กำลังทำงานอยู่\n",
    "```\n",
    "$ redis-cli ping\n",
    "PONG\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ติดตั้ง Python libraries ที่จำเป็น\n",
    "```\n",
    "$ pip install numpy\n",
    "$ pip install scipy h5py\n",
    "$ pip install tensorflow \n",
    "$ pip install keras\n",
    "$ pip install flask gevent\n",
    "$ pip install imutils requests\n",
    "$ pip install redis\n",
    "$ pip install Pillow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เวอร์ชั่นแรก ใช้ Pre-trained model ของ Keras (ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_keras_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_keras_server.py\n",
    "# USAGE\n",
    "# Start the server:\n",
    "#       python run_keras_server.py\n",
    "# Submit a request via cURL:\n",
    "#       curl -X POST -F image=@jemma.png 'http://localhost:5000/predict'\n",
    "# Submita a request via Python:\n",
    "#       python simple_request.py \n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from threading import Thread\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "import flask\n",
    "import redis\n",
    "import uuid\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import io\n",
    "\n",
    "# constants for image dimensions and datatype\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_CHANS = 3\n",
    "IMAGE_DTYPE = 'float32'\n",
    "\n",
    "# constants for server queueing\n",
    "IMAGE_QUEUE = \"image_queue\"\n",
    "BATCH_SIZE = 32\n",
    "SERVER_SLEEP = 0.25\n",
    "CLIENT_SLEEP = 0.25\n",
    "\n",
    "# start Flask Server\n",
    "app = flask.Flask(__name__)\n",
    "# connect to Redis\n",
    "db = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
    "# initialize the model variable\n",
    "model = None\n",
    "\n",
    "def base64_encode_image(a):\n",
    "    \"\"\"serialize binary image a to base64 string.\"\"\"\n",
    "    return base64.b64encode(a).decode(\"utf-8\")\n",
    "\n",
    "def base64_decode_image(a, dtype, shape):\n",
    "    \"\"\"de-serialize base64 string to numpy array.\"\"\"\n",
    "    if sys.version_info.major == 3:\n",
    "        a = bytes(a, encoding='utf-8')\n",
    "\n",
    "    a = np.frombuffer(base64.decodestring(a), dtype=dtype)\n",
    "    a = a.reshape(shape)\n",
    "    return a\n",
    "\n",
    "def prepare_image(image, target):\n",
    "    \"\"\"pre-process the image.\"\"\"\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "    image = image.resize(target)\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def classify_process():\n",
    "    \"\"\"Keras Model Server\"\"\"\n",
    "    \n",
    "    print(\"* loading model...\")\n",
    "    # load the pretrained-keras model\n",
    "    # you can replace this with your own model\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    print(\"* model loaded...\")\n",
    "\n",
    "    # pool for new images to classify\n",
    "    while True:\n",
    "        \n",
    "        # poll next batch of images from the Redis queue\n",
    "        queue = db.lrange(IMAGE_QUEUE, 0, BATCH_SIZE - 1)\n",
    "        imageIDs = []\n",
    "        batch = None\n",
    "        for q in queue:\n",
    "            q = json.loads(q.decode(\"utf-8\"))\n",
    "            image = base64_decode_image(q[\"image\"], IMAGE_DTYPE, \n",
    "                    (1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANS))\n",
    "            if batch is None:\n",
    "                batch = image\n",
    "            else:\n",
    "                batch = np.vstack([batch, image])\n",
    "            imageIDs.append(q[\"id\"])\n",
    "\n",
    "        # predict all images in the batch\n",
    "        if len(imageIDs) > 0:\n",
    "            print(\"* batch size: {}\".format(batch.shape))\n",
    "            preds = model.predict(batch)\n",
    "            \n",
    "            # construct results records \n",
    "            results = imagenet_utils.decode_predictions(preds)\n",
    "            for (imageID, resultSet) in zip(imageIDs, results):\n",
    "                output = []\n",
    "\n",
    "                for (imagenetID, label, prob) in resultSet:\n",
    "                    r = {'label': label, 'probability': float(prob)}\n",
    "                    output.append(r)\n",
    "                    \n",
    "                # stores the results in the Redis queue\n",
    "                db.set(imageID, json.dumps(output))\n",
    "            \n",
    "            # delete processed images from the queue\n",
    "            db.ltrim(IMAGE_QUEUE, len(imageIDs), -1)\n",
    "            \n",
    "        # take a nap....\n",
    "        time.sleep(SERVER_SLEEP)\n",
    "\n",
    "        \n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = {\"success\": False}\n",
    "    if flask.request.method == \"POST\":\n",
    "        if flask.request.files.get(\"image\"):\n",
    "            # read and prepare the image\n",
    "            image = flask.request.files[\"image\"].read()\n",
    "            image = Image.open(io.BytesIO(image))\n",
    "            image = prepare_image(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "\n",
    "            # ensure that numpy array is C-contiguous as well,\n",
    "            # otherwise we won't be able to serialize it\n",
    "            image = image.copy(order=\"C\")\n",
    "            \n",
    "            # generate a unique ID\n",
    "            k = str(uuid.uuid4())\n",
    "            # create a new image record in the queue\n",
    "            d = {\"id\": k, \"image\": base64_encode_image(image)}\n",
    "            db.rpush(IMAGE_QUEUE, json.dumps(d))\n",
    "            \n",
    "            # Repeated poll the results from the queue\n",
    "            # If the prediction has already finished, \n",
    "            # read the results and delete the record from the queue\n",
    "            while True:\n",
    "                output = db.get(k)\n",
    "                if output is not None:\n",
    "                    output = output.decode(\"utf-8\")\n",
    "                    data[\"predictions\"] = json.loads(output)\n",
    "                    db.delete(k)\n",
    "                    break\n",
    "                # take a nap...\n",
    "                time.sleep(CLIENT_SLEEP)\n",
    "            data[\"success\"] = True\n",
    "\n",
    "    return flask.jsonify(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"* starting model service...\")\n",
    "    t = Thread(target=classify_process, args=())\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "    print(\"* starting web service ...\")\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เวอร์ชั่นที่สอง ใช้โมเดลที่เทรนและจัดเก็บไว้ในไฟล์ `cats_and_dogs-vgg16.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_keras_server2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_keras_server2.py\n",
    "# USAGE\n",
    "# Start the server:\n",
    "#       python run_keras_server.py\n",
    "# Submit a request via cURL:\n",
    "#       curl -X POST -F image=@jemma.png 'http://localhost:5000/predict'\n",
    "# Submita a request via Python:\n",
    "#       python simple_request.py \n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "import keras.models\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from threading import Thread\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "import flask\n",
    "import redis\n",
    "import uuid\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import io\n",
    "\n",
    "# constants for image dimensions and datatype\n",
    "IMAGE_WIDTH = 150\n",
    "IMAGE_HEIGHT = 150\n",
    "IMAGE_CHANS = 3\n",
    "IMAGE_DTYPE = 'float32'\n",
    "\n",
    "# constants for server queueing\n",
    "IMAGE_QUEUE = \"image_queue\"\n",
    "BATCH_SIZE = 32\n",
    "SERVER_SLEEP = 0.25\n",
    "CLIENT_SLEEP = 0.25\n",
    "\n",
    "# start Flask Server\n",
    "app = flask.Flask(__name__)\n",
    "# connect to Redis\n",
    "db = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
    "# initialize the model variable\n",
    "model = None\n",
    "\n",
    "def base64_encode_image(a):\n",
    "    \"\"\"serialize binary image a to base64 string.\"\"\"\n",
    "    return base64.b64encode(a).decode(\"utf-8\")\n",
    "\n",
    "def base64_decode_image(a, dtype, shape):\n",
    "    \"\"\"de-serialize base64 string to numpy array.\"\"\"\n",
    "    if sys.version_info.major == 3:\n",
    "        a = bytes(a, encoding='utf-8')\n",
    "\n",
    "    a = np.frombuffer(base64.decodestring(a), dtype=dtype)\n",
    "    a = a.reshape(shape)\n",
    "    return a\n",
    "\n",
    "def prepare_image(image, target):\n",
    "    \"\"\"pre-process the image.\"\"\"\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "    image = image.resize(target)\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def classify_process():\n",
    "    \"\"\"Keras Model Server\"\"\"\n",
    "    \n",
    "    print(\"* loading model...\")\n",
    "    # load the pretrained-keras model\n",
    "    # you can replace this with your own model\n",
    "    model = keras.models.load_model('cats_and_dogs-vgg16.h5')\n",
    "    print(\"* model loaded...\")\n",
    "\n",
    "    # pool for new images to classify\n",
    "    while True:\n",
    "        \n",
    "        # poll next batch of images from the Redis queue\n",
    "        queue = db.lrange(IMAGE_QUEUE, 0, BATCH_SIZE - 1)\n",
    "        imageIDs = []\n",
    "        batch = None\n",
    "        for q in queue:\n",
    "            q = json.loads(q.decode(\"utf-8\"))\n",
    "            image = base64_decode_image(q[\"image\"], IMAGE_DTYPE, \n",
    "                    (1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANS))\n",
    "            if batch is None:\n",
    "                batch = image\n",
    "            else:\n",
    "                batch = np.vstack([batch, image])\n",
    "            imageIDs.append(q[\"id\"])\n",
    "\n",
    "        # predict all images in the batch\n",
    "        if len(imageIDs) > 0:\n",
    "            print(\"* batch size: {}\".format(batch.shape))\n",
    "            preds = model.predict(batch)\n",
    "            \n",
    "            # construct results records \n",
    "            for (imageID, resultSet) in zip(imageIDs, preds):\n",
    "                output = []\n",
    "\n",
    "                for pred in resultSet:\n",
    "                    if pred:\n",
    "                        label = 'a dog'\n",
    "                    else:\n",
    "                        label = 'a cat'\n",
    "                    r = {'label': label, 'probability': None}\n",
    "                    output.append(r)\n",
    "                    \n",
    "                # stores the results in the Redis queue\n",
    "                db.set(imageID, json.dumps(output))\n",
    "            \n",
    "            # delete processed images from the queue\n",
    "            db.ltrim(IMAGE_QUEUE, len(imageIDs), -1)\n",
    "            \n",
    "        # take a nap....\n",
    "        time.sleep(SERVER_SLEEP)\n",
    "\n",
    "        \n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = {\"success\": False}\n",
    "    if flask.request.method == \"POST\":\n",
    "        if flask.request.files.get(\"image\"):\n",
    "            # read and prepare the image\n",
    "            image = flask.request.files[\"image\"].read()\n",
    "            image = Image.open(io.BytesIO(image))\n",
    "            image = prepare_image(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "\n",
    "            # ensure that numpy array is C-contiguous as well,\n",
    "            # otherwise we won't be able to serialize it\n",
    "            image = image.copy(order=\"C\")\n",
    "            \n",
    "            # generate a unique ID\n",
    "            k = str(uuid.uuid4())\n",
    "            # create a new image record in the queue\n",
    "            d = {\"id\": k, \"image\": base64_encode_image(image)}\n",
    "            db.rpush(IMAGE_QUEUE, json.dumps(d))\n",
    "            \n",
    "            # Repeated poll the results from the queue\n",
    "            # If the prediction has already finished, \n",
    "            # read the results and delete the record from the queue\n",
    "            while True:\n",
    "                output = db.get(k)\n",
    "                if output is not None:\n",
    "                    output = output.decode(\"utf-8\")\n",
    "                    data[\"predictions\"] = json.loads(output)\n",
    "                    db.delete(k)\n",
    "                    break\n",
    "                # take a nap...\n",
    "                time.sleep(CLIENT_SLEEP)\n",
    "            data[\"success\"] = True\n",
    "\n",
    "    return flask.jsonify(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"* starting model service...\")\n",
    "    t = Thread(target=classify_process, args=())\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "    print(\"* starting web service ...\")\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
